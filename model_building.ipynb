{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt  \n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['type', 'date', 'moving_time', 'activity_id', 'name', 'distance',\n",
       "       'elevation gain', 'trainer', 'average_speed', 'max_speed',\n",
       "       'average_watts', 'suffer_score', 'average_heartrate', 'average_cadence',\n",
       "       'kilojoules', 'gear_id', 'average_temp', 'start_longitude',\n",
       "       'start_latitude', 'timezone', 'location_city', 'location_state',\n",
       "       'location_country', 'year', 'month', 'mnth_yr', 'day', 'dow',\n",
       "       'week_number', 'hour', 'moving_time (minutes)'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "df = pd.read_csv('workouts_cleaned.csv', index_col=0)\n",
    "\n",
    "# choose relevant columns \n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://towardsdatascience.com/categorical-encoding-using-label-encoding-and-one-hot-encoder-911ef77fb5bd\n",
    "df['type'] = df['type'].astype('category')\n",
    "df['type_Cat'] = df['type'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = df[['type','type_Cat','distance',\n",
    "       'elevation gain', 'trainer', 'average_speed', 'max_speed',\n",
    "       'average_watts', 'suffer_score', 'average_heartrate', 'average_cadence',\n",
    "       'kilojoules', 'gear_id', 'average_temp', 'timezone', 'location_city', 'location_state',\n",
    "       'location_country', 'year', 'month', 'mnth_yr', 'day', 'dow',\n",
    "       'week_number', 'hour', 'moving_time (minutes)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['type_Cat', 'distance', 'elevation gain', 'trainer', 'average_speed',\n",
       "       'max_speed', 'average_watts', 'suffer_score', 'average_heartrate',\n",
       "       'average_cadence',\n",
       "       ...\n",
       "       'mnth_yr_2020-11', 'mnth_yr_2020-12', 'mnth_yr_2021-01', 'dow_Friday',\n",
       "       'dow_Monday', 'dow_Saturday', 'dow_Sunday', 'dow_Thursday',\n",
       "       'dow_Tuesday', 'dow_Wednesday'],\n",
       "      dtype='object', length=175)"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "# get dummy data \n",
    "df_dum = pd.get_dummies(df_model)\n",
    "df_dum.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   type_Cat  distance  elevation gain  trainer  average_speed  max_speed  \\\n",
       "0         2      2.01              26        0              5          5   \n",
       "1         2      1.17              26        0              5          5   \n",
       "2         5      0.00               0        1              0          0   \n",
       "3         0      3.71             740        0              3          3   \n",
       "4         4      0.75              27        0              3          3   \n",
       "\n",
       "   average_watts  suffer_score  average_heartrate  average_cadence  ...  \\\n",
       "0            0.0          43.0              162.5              0.0  ...   \n",
       "1            0.0          35.0              169.5              0.0  ...   \n",
       "2            0.0          11.0              136.3              0.0  ...   \n",
       "3            0.0          40.0              133.3              0.0  ...   \n",
       "4            0.0           3.0              124.6              0.0  ...   \n",
       "\n",
       "   mnth_yr_2020-11  mnth_yr_2020-12  mnth_yr_2021-01  dow_Friday  dow_Monday  \\\n",
       "0                0                0                1           0           1   \n",
       "1                0                0                1           0           0   \n",
       "2                0                0                1           0           0   \n",
       "3                0                0                1           0           0   \n",
       "4                0                0                1           1           0   \n",
       "\n",
       "   dow_Saturday  dow_Sunday  dow_Thursday  dow_Tuesday  dow_Wednesday  \n",
       "0             0           0             0            0              0  \n",
       "1             0           1             0            0              0  \n",
       "2             0           1             0            0              0  \n",
       "3             1           0             0            0              0  \n",
       "4             0           0             0            0              0  \n",
       "\n",
       "[5 rows x 175 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>type_Cat</th>\n      <th>distance</th>\n      <th>elevation gain</th>\n      <th>trainer</th>\n      <th>average_speed</th>\n      <th>max_speed</th>\n      <th>average_watts</th>\n      <th>suffer_score</th>\n      <th>average_heartrate</th>\n      <th>average_cadence</th>\n      <th>...</th>\n      <th>mnth_yr_2020-11</th>\n      <th>mnth_yr_2020-12</th>\n      <th>mnth_yr_2021-01</th>\n      <th>dow_Friday</th>\n      <th>dow_Monday</th>\n      <th>dow_Saturday</th>\n      <th>dow_Sunday</th>\n      <th>dow_Thursday</th>\n      <th>dow_Tuesday</th>\n      <th>dow_Wednesday</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>2.01</td>\n      <td>26</td>\n      <td>0</td>\n      <td>5</td>\n      <td>5</td>\n      <td>0.0</td>\n      <td>43.0</td>\n      <td>162.5</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1.17</td>\n      <td>26</td>\n      <td>0</td>\n      <td>5</td>\n      <td>5</td>\n      <td>0.0</td>\n      <td>35.0</td>\n      <td>169.5</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>0.00</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>11.0</td>\n      <td>136.3</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>3.71</td>\n      <td>740</td>\n      <td>0</td>\n      <td>3</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>40.0</td>\n      <td>133.3</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0.75</td>\n      <td>27</td>\n      <td>0</td>\n      <td>3</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>124.6</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 175 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "df_dum.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "#making sure none of my training data has any NaNs\n",
    "nan_values = df_dum.isna()\n",
    "nan_columns = nan_values.any()\n",
    "\n",
    "columns_with_nan = df_dum.columns[nan_columns].tolist()\n",
    "print(columns_with_nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_dum.drop('type_Cat', axis =1)\n",
    "y = df_dum.type_Cat.values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "source": [
    "### Logistic Regression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(random_state=0).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[  0   0   2   0   0   0   0]\n [  0 163   4   0   0   0   0]\n [  1   0  61   0   0   1   0]\n [  0   0   2   0   0   0   0]\n [  0   0   1   0  12   1   0]\n [  0   0   4   0   0   2   0]\n [  0   0   2   0   0   0   0]]\n              precision    recall  f1-score   support\n\n           0       0.00      0.00      0.00         2\n           1       1.00      0.98      0.99       167\n           2       0.80      0.97      0.88        63\n           3       0.00      0.00      0.00         2\n           4       1.00      0.86      0.92        14\n           5       0.50      0.33      0.40         6\n           6       0.00      0.00      0.00         2\n\n    accuracy                           0.93       256\n   macro avg       0.47      0.45      0.46       256\nweighted avg       0.92      0.93      0.92       256\n\n0.9296875\n"
     ]
    }
   ],
   "source": [
    "y_pred = lr.predict(X_test)\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "source": [
    "### Random Forrest with Grid Search For Model Optimization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'n_estimators': 200}\nrf: 0.984375\n[[  1   0   1   0   0   0   0]\n [  0 167   0   0   0   0   0]\n [  0   0  63   0   0   0   0]\n [  0   0   0   1   0   1   0]\n [  0   0   0   0  14   0   0]\n [  0   0   0   0   0   6   0]\n [  0   0   0   0   0   2   0]]\n              precision    recall  f1-score   support\n\n           0       1.00      0.50      0.67         2\n           1       1.00      1.00      1.00       167\n           2       0.98      1.00      0.99        63\n           3       1.00      0.50      0.67         2\n           4       1.00      1.00      1.00        14\n           5       0.67      1.00      0.80         6\n           6       0.00      0.00      0.00         2\n\n    accuracy                           0.98       256\n   macro avg       0.81      0.71      0.73       256\nweighted avg       0.98      0.98      0.98       256\n\n0.984375\n"
     ]
    }
   ],
   "source": [
    "# random forrest with grid search\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#create a new random forest classifier\n",
    "rf = RandomForestClassifier()\n",
    "#create a dictionary of all values we want to test for n_estimators\n",
    "params_rf = {'n_estimators': [50, 100, 200]}\n",
    "#use gridsearch to test all values for n_estimators\n",
    "rf_gs = GridSearchCV(rf, params_rf, cv=5)\n",
    "#fit model to training data\n",
    "rf_gs.fit(X_train, y_train)\n",
    "#save best model\n",
    "rf_best = rf_gs.best_estimator_\n",
    "#check best n_estimators value\n",
    "print(rf_gs.best_params_)\n",
    "print('rf: {}'.format(rf_best.score(X_test, y_test)))\n",
    "\n",
    "y_pred = rf_best.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "source": [
    "### XGBoost"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[  2   0   0   0   0   0   0]\n [  0 167   0   0   0   0   0]\n [  0   0  63   0   0   0   0]\n [  0   0   0   2   0   0   0]\n [  0   0   0   0  14   0   0]\n [  0   0   0   0   0   6   0]\n [  0   0   0   0   0   0   2]]\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00         2\n           1       1.00      1.00      1.00       167\n           2       1.00      1.00      1.00        63\n           3       1.00      1.00      1.00         2\n           4       1.00      1.00      1.00        14\n           5       1.00      1.00      1.00         6\n           6       1.00      1.00      1.00         2\n\n    accuracy                           1.00       256\n   macro avg       1.00      1.00      1.00       256\nweighted avg       1.00      1.00      1.00       256\n\n1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "XG = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,max_depth=1, random_state=0).fit(X_train, y_train)\n",
    "XG.score(X_test, y_test)\n",
    "\n",
    "y_pred = XG.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Theoretically could do ensemble models but XGBoost has an accuracy of 100%. Starting to understand why this type of model wins Kaggle competions all the time. \n",
    "# I could theretically plot an ROC curve but I am very confident in my XGBoost model"
   ]
  }
 ]
}